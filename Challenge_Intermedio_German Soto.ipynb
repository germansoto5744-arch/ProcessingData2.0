{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis y Modelo de Regresión Logística para Predecir la Calidad del Vino\n",
    "# =========================================================================\n",
    "\n",
    "# ## Introducción\n",
    "# Este notebook está diseñado para cargar, explorar y preprocesar el dataset de calidad de vinos, y entrenar un modelo de regresión logística utilizando PySpark en un entorno de Databricks.\n",
    "\n",
    "# ## 1. Configuración de Databricks y Bibliotecas\n",
    "# Importamos las bibliotecas necesarias y configuramos la conexión con Databricks.\n",
    "\n",
    "import sys\n",
    "sys.executable\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('WineQualityPrediction')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Carga de Datos\n",
    "# Cargamos el archivo CSV con los datos del vino y revisamos las primeras filas.\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "\n",
    "gt = spark.read.csv('data/winequality-red.csv', \n",
    "                       inferSchema = True,\n",
    "                       sep=\";\", \n",
    "                       header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna \"quality\" a una variable binaria en una columna llamada \"label\"\n",
    "\n",
    "df = df.withColumn(\"label\", (col(\"quality\") >= 6).cast(\"int\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características\n",
    "\n",
    "feature_columns = [c for c in df.columns if c not in [\"quality\", \"label\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamblaje de las características en un solo vector\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de las características\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df)\n",
    "df = scaler_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo de regresión logística\n",
    "lr = LogisticRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6. Evaluación del Modelo\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área bajo la curva ROC: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Evaluador para medir el área bajo la curva ROC\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"Área bajo la curva ROC: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión y mostrar el informe de clasificación\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(f\"Exactitud del modelo: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|    1|       1.0|[0.01812103566953...|\n",
      "|    1|       1.0|[0.25500976345328...|\n",
      "|    0|       0.0|[0.79508949677236...|\n",
      "|    0|       0.0|[0.76399102429231...|\n",
      "|    1|       1.0|[0.04814519001736...|\n",
      "+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar una muestra de las predicciones\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProcBigdata25B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
